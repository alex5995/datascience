{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "from scipy.io import wavfile as wav\n",
    "import sounddevice as sd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.applications import resnet50\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2 as cv\n",
    "face_detector = cv.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nomi = ['Alex', 'Davide', 'Michela']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = joblib.load('kdtrees.joblib')\n",
    "xmin, xmax = joblib.load('minmax.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_people, labels_people, paths_people = trees[0]\n",
    "tree_dogs, labels_dogs, paths_dogs = trees[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_retrival = load_model(\"facenet_keras.h5\")\n",
    "print(\"facenet caricata\")\n",
    "\n",
    "model_audio = load_model(\"audionet.h5\")\n",
    "print(\"audionet caricata\")\n",
    "\n",
    "model_image = load_model('recognet.h5')\n",
    "print(\"imagenet caricata\")\n",
    "\n",
    "def l2_normalize(x):\n",
    "    return x / np.sqrt(np.sum(np.multiply(x, x)))\n",
    "\n",
    "def facenet(x):\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    f = model_retrival.predict(l2_normalize(x))\n",
    "    return f[0,:]\n",
    "\n",
    "def normalize(x, xmin, xmax):\n",
    "    return [(x[i,:]-xmin[i])/(xmax[i]-xmin[i]) for i in range(len(xmin))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(img):\n",
    "    \n",
    "    global k\n",
    "    global real_names\n",
    "    \n",
    "    people_max = 3\n",
    "    people_now = 0\n",
    "    \n",
    "    img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "    color = (255,0,0)\n",
    "    face = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    \n",
    "    faces = face_detector.detectMultiScale(img_gray)\n",
    "    \n",
    "    try:\n",
    "        faces = faces.tolist()\n",
    "        faces.sort()\n",
    "    except:\n",
    "        pass\n",
    "       \n",
    "    j=0\n",
    "    \n",
    "    if k%4==0:\n",
    "        \n",
    "        real_names = []\n",
    "        \n",
    "        for (x,y,w,h) in faces:\n",
    "            \n",
    "            if people_now < people_max:\n",
    "                \n",
    "                people_now += 1\n",
    "            \n",
    "                face = img[y:y+h,x:x+h,:]\n",
    "                face = cv.cvtColor(face, cv.COLOR_BGR2RGB)\n",
    "\n",
    "                img_pixels = cv.resize(face, (224, 224)) \n",
    "                img_pixels = img_to_array(img_pixels)\n",
    "                img_pixels = np.expand_dims(img_pixels, axis = 0)\n",
    "                img_pixels = resnet50.preprocess_input(img_pixels)\n",
    "                y_dist = model_image.predict(img_pixels)\n",
    "                y_dist[0][1] = min(y_dist[0][1]+0.2, 0.9876)\n",
    "                y_pred = np.argmax(y_dist)\n",
    "                y_dist = y_dist[0, y_pred]\n",
    "\n",
    "                if(y_dist > 0.6):\n",
    "                    real_names.append((nomi[y_pred], round(y_dist, 4)))\n",
    "                else:\n",
    "                    real_names.append(('unknown\\n', round(1-y_dist, 4)))\n",
    "            \n",
    "    j=0\n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        \n",
    "        if people_now < people_max:\n",
    "            \n",
    "            people_now += 1\n",
    "        \n",
    "            face = img[y:y+h,x:x+h,:]\n",
    "            face = cv.cvtColor(face, cv.COLOR_BGR2RGB)\n",
    "            cv.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            try:\n",
    "                cv.putText(img, (real_names[j][0] + ' ' + str(real_names[j][1])), (int(x), int(y-12)), \n",
    "                           cv.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            j+=1\n",
    "\n",
    "    k+=1\n",
    "    return img, face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "duration = 2\n",
    "rec_rate = 44100\n",
    "k = 0\n",
    "real_names = []\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "status=\"\"\n",
    "frase=\"Premere 'r' per registrare\"\n",
    "\n",
    "while(True):\n",
    "\n",
    "    r, frame = cap.read()\n",
    "    frame, face = process_frame(frame)\n",
    "    cv.putText(frame, frase, (15, 37), cv.FONT_HERSHEY_SIMPLEX, 0.75, (255,0,0), 2)\n",
    "    cv.imshow('Video', frame)\n",
    "    \n",
    "    # Registra premendo il tasto R\n",
    "    if cv.waitKey(20) & 0xFF == ord('r'):\n",
    "        \n",
    "        print(\"Inizio a registrare\\n\")\n",
    "        rec = sd.rec(int(duration * rec_rate), samplerate=rec_rate, channels=1, blocking=True)\n",
    "        wav.write('test.wav', rate=rec_rate, data=(rec))\n",
    "        \n",
    "        rec_rate, rec = wav.read('test.wav')\n",
    "        mfcc = librosa.feature.mfcc(rec*1.0, sr=rec_rate)\n",
    "        mfcc = np.array(normalize(mfcc, xmin, xmax))\n",
    "        mfcc = mfcc.reshape(1,mfcc.shape[1],mfcc.shape[0])\n",
    "        preds_audio = model_audio.predict(mfcc)\n",
    "        \n",
    "        if max(preds_audio[0]) < 0.60:   \n",
    "            pred_audio = 6     \n",
    "        else:   \n",
    "            pred_audio = np.argmax(preds_audio)\n",
    "            \n",
    "        if pred_audio == 0:\n",
    "            frase = \"Alex ha detto animale\"\n",
    "            status = \"Animale\"\n",
    "        elif pred_audio == 3:\n",
    "            frase = \"Alex ha detto persona\"\n",
    "            status = \"Persona\"\n",
    "        elif pred_audio == 4:\n",
    "            frase = \"Davide ha detto animale\"\n",
    "            status = \"Animale\"\n",
    "        elif pred_audio == 1:\n",
    "            frase = \"Davide ha detto persona\"\n",
    "            status = \"Persona\"\n",
    "        elif pred_audio == 2:\n",
    "            frase = \"Michela ha detto animale\"\n",
    "            status = \"Animale\"\n",
    "        elif pred_audio == 5:\n",
    "            frase = \"Michela ha detto persona\"\n",
    "            status = \"Persona\"\n",
    "        else:\n",
    "            frase = \"Sconosciuto\"\n",
    "            status = \"\"\n",
    "            \n",
    "        try:\n",
    "            frase = frase + \" con probabilita': \" + str(round(preds_audio[0][pred_audio], 4))\n",
    "        except:\n",
    "            frase = frase + \" con probabilita': \" + str(round(1-max(preds_audio[0]), 4))\n",
    "            \n",
    "        if status==\"Animale\":\n",
    "            \n",
    "            face = cv.resize(face, (160,160))\n",
    "            query_features = facenet(face).reshape(1,-1)\n",
    "            dist, ind = tree_dogs.query(query_features, k=10)\n",
    "            lista = [labels_dogs[el] for el in ind[0]]\n",
    "            print(\"Cani: \" + str(lista) + \"\\n\")\n",
    "            \n",
    "            fig = plt.figure(figsize = (25,275))\n",
    "            fig.add_subplot(1, 11, 1)\n",
    "            plt.imshow(face)\n",
    "            plt.axis('off')\n",
    "            for i in range(10): \n",
    "                image_ret = np.array(kimage.load_img(paths_dogs[ind[0][i]], target_size=(240,240)))\n",
    "                fig.add_subplot(1, 11, i+2)\n",
    "                plt.imshow(image_ret)\n",
    "                plt.axis('off')\n",
    "            plt.show()\n",
    "            \n",
    "        elif status==\"Persona\":\n",
    "            \n",
    "            face = cv.resize(face, (160,160))\n",
    "            query_features = facenet(face).reshape(1,-1)\n",
    "            dist, ind = tree_people.query(query_features, k=10)\n",
    "            lista = [labels_people[el] for el in ind[0]]\n",
    "            print(\"VIP: \" + str(lista) + \"\\n\")\n",
    "            \n",
    "            fig = plt.figure(figsize = (25,275))\n",
    "            fig.add_subplot(1, 11, 1)\n",
    "            plt.imshow(face)\n",
    "            plt.axis('off')\n",
    "            for i in range(10): \n",
    "                image_ret = np.array(kimage.load_img(paths_people[ind[0][i]], target_size=(240,240)))\n",
    "                fig.add_subplot(1, 11, i+2)\n",
    "                plt.imshow(image_ret)\n",
    "                plt.axis('off')\n",
    "            plt.show()\n",
    "        \n",
    "    # Interrompi lo streaming premendo il tasto Q\n",
    "    if cv.waitKey(20) & 0xFF == ord('q'):\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
