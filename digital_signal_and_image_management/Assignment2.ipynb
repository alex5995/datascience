{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assignment 2 - Alex Ceccotti - 790497"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import feature\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(feature_extractor, maximages=50, base_path='./classes/', extension='.jpg'):\n",
    "    labels = []\n",
    "    features = []\n",
    "    for di,d in enumerate(sorted(os.listdir(base_path))):\n",
    "        for fi,f in enumerate(sorted(os.listdir(base_path + d + '/'))):\n",
    "            if f.endswith(extension) and fi<maximages:\n",
    "                image = cv.imread(base_path + d + '/' + f, 0)\n",
    "                cur_features = feature_extractor(image)\n",
    "                features.append(cur_features)\n",
    "                labels.append(di)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, shuffle=True, random_state=1)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def lbp_features(img, P=24, R=8, shift=8, dims=16):\n",
    "    img = feature.local_binary_pattern(img, P=P, R=R, method='uniform')\n",
    "    feats = []\n",
    "    for i in range(0,img.shape[0],shift):\n",
    "        for j in range(0,img.shape[1],shift):\n",
    "            hist = np.bincount(img[i:i+dims,j:j+dims].flatten().astype(int), minlength=P+2)\n",
    "            feats.append(hist)\n",
    "    return np.array(feats)\n",
    "\n",
    "def bow_features(feats, dictionary, nwords):\n",
    "    quantized = dictionary.predict(feats)\n",
    "    t = np.bincount(quantized, minlength=nwords)\n",
    "    return t\n",
    "\n",
    "def bow(X_train, X_test, nwords, normalize=True, eps=0.001):\n",
    "    X_train_stack = np.zeros((0,X_train[0].shape[1]), dtype=np.float32)\n",
    "    for t in X_train:\n",
    "        X_train_stack = np.concatenate((X_train_stack, t))\n",
    "    if normalize:\n",
    "        X_train_mean = X_train_stack.mean(axis=0)\n",
    "        X_train_std = X_train_stack.std(axis=0)\n",
    "        X_train = [(t - X_train_mean + eps)/(X_train_std + eps) for t in X_train]\n",
    "        X_test = [(t - X_train_mean + eps)/(X_train_std + eps) for t in X_test]\n",
    "        X_train_stack = (X_train_stack - X_train_mean + eps)/(X_train_std + eps)\n",
    "    dictionary = MiniBatchKMeans(n_clusters=nwords)\n",
    "    dictionary.fit(X_train_stack)\n",
    "    X_train = [bow_features(f, dictionary, nwords) for f in X_train]\n",
    "    X_test = [bow_features(f, dictionary, nwords) for f in X_test]\n",
    "    X_train = [hist/hist.sum() for hist in X_train]\n",
    "    X_test = [hist/hist.sum() for hist in X_test]\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La funzione \"load_data\" consente di caricare delle immagini a partire da diverse cartelle, ognuna delle quali contiene immagini con una determinata label associata. Durante il caricamento delle immagini, vengono in realtà estrapolate delle feature tramite la funzione \"lbp_feature\". Viene quindi utilizzato lbp su tutta l'immagine e viene fatta scorrere una finestra. Ad ogni scorrimento si calcola l'istogramma della finestra che rappresenta una feature dell'immagine. La funzione \"bow\" crea un \"dizionario\" realizzato tramite k-means a partire dalle features normalizzate. Successivamente, tramite la funzione \"bow_feature\", ogni feature di ogni immagine viene associata ad uno dei centroidi precedentemente trovati. Le feature relative ad un'immagine diventano dunque l'istogramma normalizzato delle \"bag of words\" associate a quell'immagine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_data(feature_extractor=lambda x:\n",
    "                                                    lbp_features(x, P=24, R=8, shift=8, dims=16), maximages=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si estraggono le feature di partenza utilizzando LBP con 24 punti e raggio 8. La finestra mobile è di dimensioni 16x16 e viene fatta scorrere di 8 pixel alla volta, sia in orizzontale sia in verticale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2 = bow(X_train, X_test, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viene trovato il dizionario (con 300 \"parole\") e si trovano le feature finali per ogni immagine. Ogni immagine avrà dunque 300 feature, ognuna delle quali indica la frequenza con cui una data \"parola\" viene associata all'immagine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\alexc\\Anaconda3\\envs\\dsim\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addestramento completato in 35.259s\n",
      "Migliore combinazione di parametri:\n",
      " C: 1.5\n",
      " gamma: 300\n"
     ]
    }
   ],
   "source": [
    "#param_grid = {'C': [1, 5, 10, 50, 100, 500],\n",
    "#          'gamma': [1, 5, 10, 50, 100, 500], } \n",
    "#C=1, gamma=500\n",
    "\n",
    "param_grid = {'C': [0.5, 1, 1.5, 2],\n",
    "          'gamma': [100, 200, 300, 400, 500, 600], } \n",
    "#C=1.5, gamma=300\n",
    "\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid, cv=5, n_jobs=-1)\n",
    "\n",
    "t2 = time()\n",
    "clf = clf.fit(X_train2, y_train)\n",
    "print(\"Addestramento completato in %0.3fs\" % (time() - t2))\n",
    "\n",
    "print(\"Migliore combinazione di parametri:\")\n",
    "print(\" C: \"+str(clf.best_estimator_.C))\n",
    "print(\" gamma: \"+str(clf.best_estimator_.gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viene allenata una SVM con Cross Validation (5 folds) a partire da una griglia generica. Una volta trovati dei parametri idonei, viene fatta una ricerca più centrata sui valori così ottenuti (C=1.5 e gamma=300). I parametri finali ottenuti con il secondo training sono C=1.5 e gamma=300."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report di classificazione:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73       149\n",
      "           1       0.74      0.70      0.72       151\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       300\n",
      "   macro avg       0.73      0.73      0.73       300\n",
      "weighted avg       0.73      0.73      0.73       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test2)\n",
    "\n",
    "print(\"Report di classificazione:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I risulti sul test set sono quelli riportati nella tabella soprastante. In particolare, si ottiene un f1-score pari a 0.73."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice di confusione:\n",
      "[[112  37]\n",
      " [ 45 106]]\n",
      "Accuracy: 0.727\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrice di confusione:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "\n",
    "print(\"Accuracy: \" + str(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Qui sopra viene riportata la matrice di confusione e si evidenzia il risultato in termini di accuracy: 0.727."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
