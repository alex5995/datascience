{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uoBwzxAPo9fK"
   },
   "source": [
    "#### Assignment 4 - Alex Ceccotti - 790497"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KAAX5jHCpCxY"
   },
   "source": [
    "Dal momento che l'assignment è stato sviluppato in google colab, è stato necessario caricare le credenziali di Kaggle e posizionarle nell'opportuna directory. La guida all'utilizzo della API di Kaggle è presente al seguente link: https://github.com/Kaggle/kaggle-api. Viene poi fatto il download del dataset delle icone (lo stesso dell'assignment 3) direttamente da Kaggle tramite API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kPHjMsbEjDeI"
   },
   "outputs": [],
   "source": [
    "!mkdir /root/.kaggle/\n",
    "!cp kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "GaJrLdDkk3NW",
    "outputId": "4c7a29ca-0215-48cc-b2b8-94db4370ad36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading icons50.zip to /content\n",
      " 95% 82.0M/86.7M [00:01<00:00, 56.8MB/s]\n",
      "100% 86.7M/86.7M [00:01<00:00, 74.6MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d danhendrycks/icons50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8OJ8dmHppwlP"
   },
   "source": [
    "\n",
    "Il dataset viene poi decompresso e posizionato nella cartella my_data, che conterrà dunque 50 sottocartelle, ognuna della quali conterrà le immagini di una data classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fa0uSFWlQd8"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('icons50.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('my_folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RDq212IWmeZb"
   },
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('my_folder/Icons-50.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('Icons-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WseHncMdmv4U"
   },
   "outputs": [],
   "source": [
    "!cp -r Icons-50/Icons-50 my_data\n",
    "!rm icons50.zip\n",
    "!rm -r my_folder\n",
    "!rm -r Icons-50\n",
    "!rm my_data/README.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bnzPAFavnUaQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from random import shuffle\n",
    "\n",
    "from keras.applications import vgg19\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "\n",
    "\n",
    "def load_data(directory, maximages=-1):\n",
    "    base_path = './'+directory+'/'\n",
    "    labels = []\n",
    "    features = []\n",
    "    for di,d in enumerate(sorted(os.listdir(base_path))):\n",
    "        for fi,f in enumerate(sorted(os.listdir(base_path + d + '/'))):\n",
    "            if f.endswith('.png') and (fi<maximages or maximages==-1):\n",
    "                image = kimage.load_img(base_path + d + '/' + f, target_size=(224, 224))\n",
    "                features.append(image)\n",
    "                labels.append(di)\n",
    "        print(\"Caricate \" + str(fi+1) + \" immagini dalla cartella numero \" + str(di) + \" (\" + d + \")\")\n",
    "        fi = -1\n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, shuffle=True, random_state=1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, shuffle=True, random_state=1)\n",
    "    return X_train, X_val, X_test, pd.get_dummies(y_train).as_matrix(), pd.get_dummies(y_val).as_matrix(), pd.get_dummies(y_test).as_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HgJ_Js6ertSG"
   },
   "source": [
    "La funzione load_data carica le immagini in una lista, che viene poi splittata in training, validation e test set. In questa fase le immagini non sono ancora state trasformate in array e non è stato ancora fatto alcun genere di preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 867
    },
    "colab_type": "code",
    "id": "lDT3O37ApIK_",
    "outputId": "79985aba-3865-4321-facf-67bd5d5195c3",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricate 76 immagini dalla cartella numero 0 (airplane)\n",
      "Caricate 392 immagini dalla cartella numero 1 (arrow_directions)\n",
      "Caricate 192 immagini dalla cartella numero 2 (ball)\n",
      "Caricate 100 immagini dalla cartella numero 3 (biking)\n",
      "Caricate 229 immagini dalla cartella numero 4 (bird)\n",
      "Caricate 90 immagini dalla cartella numero 5 (blade)\n",
      "Caricate 289 immagini dalla cartella numero 6 (boat)\n",
      "Caricate 208 immagini dalla cartella numero 7 (books)\n",
      "Caricate 312 immagini dalla cartella numero 8 (building)\n",
      "Caricate 160 immagini dalla cartella numero 9 (bunny_ears)\n",
      "Caricate 105 immagini dalla cartella numero 10 (cartwheeling)\n",
      "Caricate 417 immagini dalla cartella numero 11 (clock)\n",
      "Caricate 141 immagini dalla cartella numero 12 (cloud)\n",
      "Caricate 63 immagini dalla cartella numero 13 (disk)\n",
      "Caricate 238 immagini dalla cartella numero 14 (drinks)\n",
      "Caricate 429 immagini dalla cartella numero 15 (emotion_face)\n",
      "Caricate 119 immagini dalla cartella numero 16 (envelope)\n",
      "Caricate 455 immagini dalla cartella numero 17 (family)\n",
      "Caricate 158 immagini dalla cartella numero 18 (fast_train)\n",
      "Caricate 363 immagini dalla cartella numero 19 (feline)\n",
      "Caricate 446 immagini dalla cartella numero 20 (flag)\n",
      "Caricate 197 immagini dalla cartella numero 21 (flower)\n",
      "Caricate 126 immagini dalla cartella numero 22 (footwear)\n",
      "Caricate 98 immagini dalla cartella numero 23 (golfing)\n",
      "Caricate 429 immagini dalla cartella numero 24 (hand)\n",
      "Caricate 108 immagini dalla cartella numero 25 (hat)\n",
      "Caricate 396 immagini dalla cartella numero 26 (heart)\n",
      "Caricate 187 immagini dalla cartella numero 27 (holding_hands)\n",
      "Caricate 356 immagini dalla cartella numero 28 (japanese_ideograph)\n",
      "Caricate 84 immagini dalla cartella numero 29 (kiss)\n",
      "Caricate 92 immagini dalla cartella numero 30 (lock)\n",
      "Caricate 96 immagini dalla cartella numero 31 (mailbox)\n",
      "Caricate 183 immagini dalla cartella numero 32 (marine_animals)\n",
      "Caricate 64 immagini dalla cartella numero 33 (medal)\n",
      "Caricate 136 immagini dalla cartella numero 34 (money)\n",
      "Caricate 134 immagini dalla cartella numero 35 (monkey)\n",
      "Caricate 236 immagini dalla cartella numero 36 (moon)\n",
      "Caricate 78 immagini dalla cartella numero 37 (mountain)\n",
      "Caricate 204 immagini dalla cartella numero 38 (numbers)\n",
      "Caricate 88 immagini dalla cartella numero 39 (phone)\n",
      "Caricate 154 immagini dalla cartella numero 40 (prohibit_sign)\n",
      "Caricate 241 immagini dalla cartella numero 41 (star)\n",
      "Caricate 105 immagini dalla cartella numero 42 (surfing)\n",
      "Caricate 103 immagini dalla cartella numero 43 (tree)\n",
      "Caricate 90 immagini dalla cartella numero 44 (umbrella)\n",
      "Caricate 244 immagini dalla cartella numero 45 (vehicle)\n",
      "Caricate 138 immagini dalla cartella numero 46 (water_polo)\n",
      "Caricate 487 immagini dalla cartella numero 47 (worker)\n",
      "Caricate 61 immagini dalla cartella numero 48 (wrestling)\n",
      "Caricate 103 immagini dalla cartella numero 49 (writing_utensil)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, X_test, y_train, y_val, y_test = load_data('my_data', maximages=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xFvgjIFYzMLP",
    "outputId": "88ed4229-7e73-4145-8870-0b816aee7be7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6300, 50) (700, 50) (3000, 50)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape, y_val.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ugiZiGKEspmh"
   },
   "source": [
    "Vengono caricati i pesi della rete VGG19 con average pooling escludendo gli strati fully connected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gOIymGDfpYfJ"
   },
   "outputs": [],
   "source": [
    "net = vgg19.VGG19(include_top=False, weights='imagenet', pooling='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EcEw_6CKsvSB"
   },
   "source": [
    "Vengono dunque aggiunti due strati fully connected con 1024 neuroni ciascuno e con funzione di attivazione relu. I pesi di questi strati andranno tunati, mentre quelli caricati precedentemente vengono fissati. Infine, viene aggiunto uno strato con 50 neuroni (uno per classe) con funzione di attivazione softmax. Viene utilizzato l'ottimizzatore \"adam\" con learning rate pari a 0.0001 e funzione di perdita \"categorical crossentropy\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ow9MJfD0p0VB"
   },
   "outputs": [],
   "source": [
    "for layer in net.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = net.output\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "pred = Dense(y_train.shape[1], activation='softmax')(x)\n",
    "\n",
    "my_net = Model(inputs=net.input, outputs=pred)\n",
    "\n",
    "adam = optimizers.Adam(lr=0.0001)\n",
    "my_net.compile(optimizer=adam, loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HtOXKdiGtyCl"
   },
   "source": [
    "Viene eseguito il preprocessing delle immagini di validation e di test necessario per passare tali immagini alla rete VGG19."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DPSgW2w-Yk3k"
   },
   "outputs": [],
   "source": [
    "X_val_preproc = []\n",
    "for image in X_val:\n",
    "    image = kimage.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = vgg19.preprocess_input(image)\n",
    "    X_val_preproc.append(image)\n",
    "X_val_preproc = np.array(X_val_preproc).reshape(-1, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b6adu_TzchaN"
   },
   "outputs": [],
   "source": [
    "X_test_preproc = []\n",
    "for image in X_test:\n",
    "    image = kimage.img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = vgg19.preprocess_input(image)\n",
    "    X_test_preproc.append(image)\n",
    "X_test_preproc = np.array(X_test_preproc).reshape(-1, 224, 224, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3SgNy5WYt2Cn"
   },
   "source": [
    "Viene trainata la rete passando batch di 64 immagini alla volta. Ad ogni batch viene fatto il preprocessing di VGG19 trasformando inoltre le immagini del batch in array. Questa procedura è stata fatta per ogni batch e non tutta in una volta per motivi di spazio di memoria. Alla fine di ogni epoca, viene valutata la loss sul validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1292
    },
    "colab_type": "code",
    "id": "DaTuNL_eOzYn",
    "outputId": "ed8b08d2-e94d-4a90-ecb0-0aee58abe8df",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoca 1 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 9s 12ms/step\n",
      "1.1243261752809797\n",
      "Epoca 2 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.580847282750266\n",
      "Epoca 3 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.43630905049187796\n",
      "Epoca 4 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.3658160594531468\n",
      "Epoca 5 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.32145916053227014\n",
      "Epoca 6 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.2940525221824646\n",
      "Epoca 7 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.27871462532452174\n",
      "Epoca 8 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.26640990206173487\n",
      "Epoca 9 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.25657734496252876\n",
      "Epoca 10 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.2481038817337581\n",
      "Epoca 11 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.24051866122654506\n",
      "Epoca 12 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.23378253979342326\n",
      "Epoca 13 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.22835751371724264\n",
      "Epoca 14 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.2243794745206833\n",
      "Epoca 15 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.22151494187968118\n",
      "Epoca 16 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.21944260137421745\n",
      "Epoca 17 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.21794054329395293\n",
      "Epoca 18 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.21649612179824285\n",
      "Epoca 19 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.21490373849868774\n",
      "Epoca 20 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.21355962898050035\n",
      "Epoca 21 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.21232252282755715\n",
      "Epoca 22 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.2110877365725381\n",
      "Epoca 23 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.21007068301950182\n",
      "Epoca 24 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.20912434944084712\n",
      "Epoca 25 finita. Loss sul validation set: \n",
      "700/700 [==============================] - 7s 11ms/step\n",
      "0.2084342108454023\n"
     ]
    }
   ],
   "source": [
    "batch_size=128\n",
    "for i in range(25):\n",
    "    for j in range((len(X_train)//batch_size)+1):\n",
    "        batch = X_train[batch_size*j:batch_size*(j+1)]\n",
    "        y = y_train[batch_size*j:batch_size*(j+1),]\n",
    "        x = []\n",
    "        for image in batch:\n",
    "            image = kimage.img_to_array(image)\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "            image = vgg19.preprocess_input(image)\n",
    "            x.append(image.reshape(224,224,3))\n",
    "        x = np.array(x)\n",
    "        my_net.train_on_batch(x, y)\n",
    "    print(\"Epoca \" + str(i+1) + \" finita. Loss sul validation set: \")\n",
    "    print(my_net.evaluate(x=X_val_preproc, y=y_val, batch_size=128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pP8u8Lr_-oW3"
   },
   "source": [
    "Dopo aver allenato la rete sui dati di training per 25 epoche, vengono fatte le predizioni sul test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whX8aiZh3ZGw"
   },
   "outputs": [],
   "source": [
    "y_pred = my_net.predict(X_test_preproc, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j3YX2DfV-1V7"
   },
   "source": [
    "Gli output della rete sono dei vettori con 50 elementi. L'indice dell'elemento con valore maggiore sarà dunque la classe predetta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0uid3pfx6ubB"
   },
   "outputs": [],
   "source": [
    "my_pred = np.argmax(y_pred, axis=1)\n",
    "my_true = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1003
    },
    "colab_type": "code",
    "id": "xi1iHTV07OJ_",
    "outputId": "4173b871-950c-4290-e2de-c5897a9cdde5",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report di classificazione:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.87      0.93        23\n",
      "           1       0.92      0.98      0.95       121\n",
      "           2       0.93      0.85      0.89        61\n",
      "           3       1.00      1.00      1.00        29\n",
      "           4       0.94      0.86      0.90        70\n",
      "           5       0.81      0.74      0.77        23\n",
      "           6       0.94      0.94      0.94        90\n",
      "           7       0.95      0.92      0.93        61\n",
      "           8       0.94      0.96      0.95        81\n",
      "           9       0.97      0.97      0.97        58\n",
      "          10       1.00      1.00      1.00        30\n",
      "          11       0.97      0.99      0.98       131\n",
      "          12       0.91      0.96      0.93        51\n",
      "          13       0.93      0.81      0.87        16\n",
      "          14       0.90      0.86      0.88        71\n",
      "          15       0.97      0.99      0.98       114\n",
      "          16       0.96      0.89      0.93        28\n",
      "          17       0.99      0.99      0.99       133\n",
      "          18       0.95      0.86      0.90        43\n",
      "          19       0.93      0.99      0.96       126\n",
      "          20       0.94      0.95      0.95       132\n",
      "          21       0.92      0.86      0.89        66\n",
      "          22       0.94      0.92      0.93        37\n",
      "          23       0.96      1.00      0.98        27\n",
      "          24       0.90      0.97      0.93       126\n",
      "          25       0.96      0.81      0.88        32\n",
      "          26       0.98      0.97      0.97       121\n",
      "          27       0.97      0.97      0.97        63\n",
      "          28       0.97      0.97      0.97       110\n",
      "          29       0.96      0.93      0.95        29\n",
      "          30       0.96      1.00      0.98        26\n",
      "          31       1.00      1.00      1.00        27\n",
      "          32       0.80      0.79      0.80        52\n",
      "          33       0.94      0.76      0.84        21\n",
      "          34       0.96      0.94      0.95        48\n",
      "          35       0.97      0.93      0.95        41\n",
      "          36       1.00      0.97      0.99        77\n",
      "          37       0.89      0.93      0.91        27\n",
      "          38       0.93      0.97      0.95        68\n",
      "          39       0.92      0.92      0.92        24\n",
      "          40       0.98      1.00      0.99        41\n",
      "          41       0.92      0.95      0.93        74\n",
      "          42       1.00      1.00      1.00        28\n",
      "          43       0.93      0.76      0.83        33\n",
      "          44       0.80      0.89      0.84        18\n",
      "          45       0.95      0.99      0.97        75\n",
      "          46       1.00      1.00      1.00        36\n",
      "          47       0.99      1.00      1.00       132\n",
      "          48       1.00      1.00      1.00        19\n",
      "          49       0.80      0.93      0.86        30\n",
      "\n",
      "   micro avg       0.95      0.95      0.95      3000\n",
      "   macro avg       0.94      0.93      0.94      3000\n",
      "weighted avg       0.95      0.95      0.95      3000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Report di classificazione:\")\n",
    "print(classification_report(my_true, my_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "colab_type": "code",
    "id": "YeEoxUF77Ukr",
    "outputId": "c8abded5-0743-4c1f-8594-fd55e8ee9ced"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice di confusione:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb9109a05f8>"
      ]
     },
     "execution_count": 60,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFLCAYAAABft66eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP/XzKh+TNwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Matrice di confusione:\")\n",
    "cm = confusion_matrix(my_true, my_pred)\n",
    "plt.imshow(cm, cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "rrS2oZJNlQv5",
    "outputId": "d5ea99e8-ef87-41e0-df5c-e32752ea9d30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9466666666666667\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \" + str(accuracy_score(my_true, my_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uo9Aqtg8CLzJ"
   },
   "source": [
    "Si ottiene un F1-score pari a 0.95 e un accuaracy pari a 0.947.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment4.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
